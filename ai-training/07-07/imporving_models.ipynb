{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b819446f-8c23-41c6-b886-1e1354b4dd6d",
   "metadata": {},
   "source": [
    "# Como melhorar um modelo de Machine Learning?\n",
    "\n",
    "Melhorar um modelo de machine learning vai muito além de trocar o algoritmo. Envolve otimizar todo o ecossistema: dados, atributos, validação e até cuidados indiretos que impactam a performance final.\n",
    "\n",
    "Abaixo, exploramos as principais áreas de atuação para melhorar um modelo de forma sólida e consciente.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Melhorias no Dataset\n",
    "\n",
    "### a) Mais dados\n",
    "- Aumentar o volume de dados pode ajudar o modelo a generalizar melhor.\n",
    "- Com mais dados, modelos mais complexos (como redes neurais ou florestas profundas) tornam-se viáveis.\n",
    "- É possível coletar mais dados reais ou gerar dados sintéticos (ex: SMOTE para classes desbalanceadas).\n",
    "\n",
    "### b) Melhor qualidade dos dados\n",
    "- Dados sujos ou inconsistentes comprometem o aprendizado.\n",
    "- Técnicas recomendadas:\n",
    "  - Tratamento de outliers\n",
    "  - Imputação de valores nulos\n",
    "  - Remoção de duplicatas\n",
    "  - Correção de inconsistências\n",
    "\n",
    "### c) Balanceamento de classes (em classificação)\n",
    "- Desequilíbrio entre classes pode levar o modelo a ignorar a classe minoritária.\n",
    "- Técnicas:\n",
    "  - Oversampling (ex: SMOTE)\n",
    "  - Undersampling\n",
    "  - Ajuste de pesos (`class_weight='balanced'`)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Melhorias nas Features (Engenharia de Atributos)\n",
    "\n",
    "### a) Feature Selection\n",
    "- Reduzir a quantidade de variáveis pode:\n",
    "  - Diminuir o overfitting\n",
    "  - Melhorar interpretabilidade\n",
    "  - Aumentar a performance\n",
    "- Ferramentas: `SelectKBest`, `RFE`, `Lasso`, análise de correlação\n",
    "\n",
    "### b) Feature Engineering\n",
    "- Criar novas variáveis a partir de dados existentes pode melhorar o desempenho do modelo.\n",
    "- Exemplos:\n",
    "  - Interações entre variáveis (`x1 * x2`)\n",
    "  - Agrupamentos (ex: média por categoria)\n",
    "  - Transformações matemáticas (log, raiz quadrada)\n",
    "\n",
    "### c) Normalização e Padronização\n",
    "- Modelos baseados em distância (KNN, SVM) exigem dados na mesma escala.\n",
    "- Técnicas:\n",
    "  - `StandardScaler`\n",
    "  - `MinMaxScaler`\n",
    "  - `RobustScaler`\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Melhorias no Modelo\n",
    "\n",
    "### a) Escolha do algoritmo\n",
    "- Testar diferentes algoritmos pode ser útil, mas não resolve problemas estruturais nos dados.\n",
    "- Exemplo: além de `LinearRegression`, testar `RandomForest`, `XGBoost`, `SVR`, entre outros.\n",
    "\n",
    "### b) Ajuste de hiperparâmetros (Hyperparameter Tuning)\n",
    "- Permite refinar o comportamento interno do modelo.\n",
    "- Ferramentas:\n",
    "  - `GridSearchCV`\n",
    "  - `RandomizedSearchCV`\n",
    "  - Otimizações avançadas como `Optuna` ou `Bayesian Optimization`\n",
    "\n",
    "### c) Regularização\n",
    "- Ajuda a evitar overfitting penalizando a complexidade do modelo.\n",
    "- Exemplos:\n",
    "  - `Ridge` e `Lasso` para regressão\n",
    "  - `max_depth`, `min_samples_leaf` para árvores\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Melhorias na Validação e Avaliação\n",
    "\n",
    "### a) Validação cruzada (Cross-validation)\n",
    "- Divide os dados em múltiplos subconjuntos (folds) para estimar melhor o desempenho real.\n",
    "\n",
    "### b) Escolha das métricas\n",
    "- Usar métricas adequadas ao problema:\n",
    "  - Classificação: `accuracy`, `precision`, `recall`, `f1`, `roc_auc`\n",
    "  - Regressão: `mae`, `mse`, `rmse`, `r2`\n",
    "\n",
    "### c) Análise de erros\n",
    "- Verificar em quais casos o modelo mais erra pode revelar padrões ocultos.\n",
    "- Perguntas úteis:\n",
    "  - Os dados estão rotulados corretamente?\n",
    "  - O erro está concentrado em alguma faixa de valor?\n",
    "  - Há viés em alguma feature?\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Outros fatores indiretamente importantes\n",
    "\n",
    "### a) Qualidade do split entre treino e teste\n",
    "- O treino e o teste devem representar bem a realidade do problema.\n",
    "- Amostras não podem estar enviesadas ou “fáceis demais”.\n",
    "\n",
    "### b) Leakage de dados\n",
    "- O modelo pode ter acesso indevido a informações futuras.\n",
    "- Exemplo: usar a média de vendas do mês futuro para prever o mês atual.\n",
    "\n",
    "### c) Interpretação e explicabilidade\n",
    "- Usar ferramentas como `SHAP`, `LIME` ou `permutation importance` ajuda a entender o modelo e identificar falhas.\n",
    "\n",
    "---\n",
    "\n",
    "## Resumo\n",
    "\n",
    "| Categoria             | Estratégias                                                    |\n",
    "|----------------------|-----------------------------------------------------------------|\n",
    "| Dados                | Coleta, limpeza, balanceamento                                  |\n",
    "| Atributos (features) | Seleção, criação, normalização                                  |\n",
    "| Modelo               | Escolha adequada, ajuste fino, regularização                    |\n",
    "| Validação            | Cross-validation, métricas adequadas, análise de erros          |\n",
    "| Cuidados extras      | Evitar leakage, splits corretos, interpretabilidade             |\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8947ae3-3b38-484a-956c-3275e1da0d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 45 46\n",
      "Accuracy: 80.00%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score: 0.82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8, 'precision': 0.78, 'recall': 0.88, 'f1': 0.82}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Lê o CSV e transforma-o em um DataFrame\n",
    "heart_disease_df = pd.read_csv(\"./dataset/heart-disease.csv\")\n",
    "\n",
    "# Divide o DataFrame em features (x) e target (y)\n",
    "X = heart_disease_df.drop(\"target\", axis = 1)\n",
    "y = heart_disease_df[\"target\"]\n",
    "\n",
    "# Importa as funções de avaliação mais comuns para modelos de classificação binária\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score \n",
    "\n",
    "# Define uma função que recebe os valores reais e valores preditos respectivamente e retorna métricas de avaliação\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"accuracy\": round(accuracy, 2),\n",
    "        \"precision\": round(precision, 2),\n",
    "        \"recall\": round(recall, 2),\n",
    "        \"f1\": round(f1, 2)\n",
    "    }\n",
    "\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1 score: {f1:.2f}')\n",
    "\n",
    "    return metrics_dict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42) # garante uniformidade aos geradores NumPy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Divide os dados (X e y) em 70% (para treino) e 30% (para posteriormente ser divido em validação e teste)\n",
    "# Passo 1: separa 70% para treino e 30% restante\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Passo 2: separa metade do 30% para validação e metade para teste\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5)\n",
    "\n",
    "print(len(X_train), len(X_valid), len(X_test))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier # importa modelo de classificação \"Random Forest\"\n",
    "\n",
    "clf = RandomForestClassifier() # intancia o modelo com hiper-parâmetros padrões\n",
    "\n",
    "clf.fit(X_train, y_train) # treina o modelo com as dados de treino\n",
    "\n",
    "y_preds = clf.predict(X_valid) # faz previsões com o modelo \"clf\" sobre os dados de validação (X_valid)\n",
    "\n",
    "# Avalia o desempenho do modelo passando à função \"evaluate_models()\" os valores reais de validação e as predições\n",
    "baseiline_metrics = evaluate_model(y_valid, y_preds)\n",
    "baseiline_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d622cbac-f793-4a28-9298-82bce6cae13d",
   "metadata": {},
   "source": [
    "## Mas afinal, o que s]ao `hiperparâmetros`?\n",
    "\n",
    "| Termo               | O que são?                                                                    | Quem define?                |\n",
    "| ------------------- | ----------------------------------------------------------------------------- | --------------------------- |\n",
    "| **Parâmetros**      | São aprendidos **pelo modelo durante o treinamento**.                         | O modelo aprende sozinho    |\n",
    "| **Hiperparâmetros** | São definidos **antes do treinamento** e controlam o comportamento do modelo. | Você (ou validação cruzada) |\n",
    "\n",
    "<br>\n",
    "\n",
    "* `Parâmetros` definem o que o modelo aprendeu\n",
    "\n",
    "* `Hiperparâmetros` definem como ele aprende\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe85534-1e26-44d2-b5fb-47461a982dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'monotonic_cst': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params() # retorna os hiperparâmetros do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bbd94d-d2d5-44ec-8d69-6d271d1f1c48",
   "metadata": {},
   "source": [
    "* ## Hyperparameter Tuning\n",
    "\n",
    "### 1. Manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955a065d-621a-4028-8dbe-83c6f2b62f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.00%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score: 0.82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8, 'precision': 0.78, 'recall': 0.88, 'f1': 0.82}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42) # garante uniformidade aos geradores NumPy\n",
    "\n",
    "clf_2 = RandomForestClassifier(\n",
    "    n_estimators = 1000,\n",
    "    max_depth=10\n",
    ") \n",
    "# Instancia um novo modelo \"RandomForestClassifier\" com hiperparâmetros específicos\n",
    "# n_estimators = 500 → 500 árvores de decisão (mais robusto, tende a reduzir o erro de generalização)\n",
    "# max_depth = 10 → cada árvore terá profundidade máxima de 10 níveis, limitando a complexidade e evitando overfitting\n",
    "\n",
    "clf_2.fit(X_train, y_train) # treina o modelo com as dados de treino\n",
    "\n",
    "y_preds_2 = clf_2.predict(X_valid) # faz previsões com o modelo \"clf\" sobre os dados de validação (X_valid)\n",
    "\n",
    "# Avalia o desempenho do modelo passando à função \"evaluate_models()\" os valores reais de validação e as predições\n",
    "clf_2_metrics = evaluate_model(y_valid, y_preds_2)\n",
    "clf_2_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e93fc54-06de-434a-ba05-be541c9ba446",
   "metadata": {},
   "source": [
    "## 2. `RandomizedSearchCV`\n",
    "\n",
    "\n",
    "\n",
    "O script a seguir usa o `RandomizedSearchCV` para fazer ajuste de hiperparâmetros de um modelo **RandomForestClassifier**, testando combinações de hiperparâmetros de forma aleatória em vez de exaustiva, o que é mais eficiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f6a350-0f25-4fcb-951a-3e52174bba17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=1000; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=1000; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=1000; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=1000; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=1200; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=1200; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=1200; total time=   2.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=1200; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=1200; total time=   2.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n"
     ]
    }
   ],
   "source": [
    "# Importa a classe \"RandomizedSearchCV\", usada para buscar hiperparâmetros de forma aleatória e eficiente\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "\n",
    "# Define o espaço de busca de hiperparâmetros\n",
    "# Contém os valores que o algoritmo pode testar para cada parâmetro do \"Random Forest\"\n",
    "grid = {\n",
    "    \"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "    \"max_depth\": [None, 5, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 4, 6],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Divide os dados (X e y) em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs = -1) \n",
    "# n_jobs = -1 → usa todos os núcleos da CPU disponíveis para paralelizar o treinamento (mais rápido)\n",
    "\n",
    "rs_clf = RandomizedSearchCV(\n",
    "    estimator = clf,\n",
    "    param_distributions = grid,\n",
    "    n_iter = 10,\n",
    "    cv = 5,\n",
    "    verbose = 2\n",
    ")\n",
    "# Instancia o RandomizedSearchCV com os seguintes argumentos:\n",
    "# estimator = clf → modelo base que será ajustado\n",
    "# param_distributions = grid → dicionário de hiperparâmetros a serem sorteados\n",
    "# n_iter = 10 → número de combinações aleatórias que serão testadas → qtd. output = n_inter * cv\n",
    "# cv = 5 → validação cruzada com 5 folds (K = 5)\n",
    "# verbose = 2 → mostra progresso da busca no console\n",
    "\n",
    "rs_clf.fit(X_train, y_train);\n",
    "# Inicia o processo de tuning:\n",
    "# sorteia 10 combinações, treina o modelo 5 vezes para cada uma (cross-validation), e armazena a melhor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dbcda36-ec9e-45bc-9d80-d1a8af77f0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_depth': 30}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_clf.best_params_ # retorna os melhores hiperparâmetros encontrados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e9eae-613d-481d-9846-293acef3816e",
   "metadata": {},
   "source": [
    "## Por que usar o RandomizedSearchCV?\n",
    "\n",
    "Fazer busca exaustiva com `GridSearchCV` pode ser muito custoso (ex: 6×5×4×3 = 360 combinações).\n",
    "\n",
    "O `RandomizedSearchCV` sorteia um número fixo de combinações (`n_iter`) e testa essas aleatoriamente.\n",
    "\n",
    "Isso permite economizar tempo e ainda assim explorar o espaço de busca com boas chances de encontrar uma configuração eficiente.\n",
    "\n",
    "---\n",
    "\n",
    "## Parâmetros principais\n",
    "\n",
    "| Parâmetro             | O que faz                                                       |\n",
    "|-----------------------|------------------------------------------------------------------|\n",
    "| `estimator`           | O modelo a ser ajustado (ex: `RandomForestClassifier`)          |\n",
    "| `param_distributions` | Dicionário com os hiperparâmetros a serem sorteados             |\n",
    "| `n_iter`              | Número de combinações aleatórias a serem testadas               |\n",
    "| `cv`                  | Quantidade de divisões para validação cruzada                   |\n",
    "| `verbose`             | Nível de detalhamento do log (ex: `2` mostra progresso na tela) |\n",
    "\n",
    "---\n",
    "\n",
    "## Vantagens\n",
    "\n",
    "- Muito mais rápido que `GridSearchCV` em grandes espaços de busca\n",
    "- Ideal para rodar em ambientes com tempo ou recursos computacionais limitados\n",
    "- Pode ser combinado com `n_jobs=-1` para paralelismo automático\n",
    "\n",
    "---\n",
    "\n",
    "## Resultado\n",
    "\n",
    "Após o `fit()`, você pode acessar:\n",
    "\n",
    "```python\n",
    "rs_clf.best_params_     # melhores hiperparâmetros encontrados\n",
    "rs_clf.best_score_      # melhor score médio obtido na validação cruzada\n",
    "rs_clf.best_estimator_  # modelo já treinado com a melhor combinação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25fc1ac9-6f67-42a2-8da7-79bc856c8a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.33%\n",
      "Precision: 0.74\n",
      "Recall: 0.90\n",
      "F1 score: 0.81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8, 'precision': 0.74, 'recall': 0.9, 'f1': 0.81}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usa o modelo \"rs_clf\", ajustado com \"RandomizedSearchCV\", para fazer previsões sobre os dados de teste (X_test)\n",
    "rs_preds = rs_clf.predict(X_test)\n",
    "\n",
    "# Avalia o desempenho do modelo passando à função \"evaluate_models()\" os valores reais de validação e as predições\n",
    "rs_clf_metrics = evaluate_model(y_test, rs_preds)\n",
    "rs_clf_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
